{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMokO91ZckhKPDFi1obQoIV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Terence0408/Teach_code/blob/master/Deep_Learning_Python_02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tQtjgxRU_Tiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5266d3e9-b793-4148-faef-4da69ae05630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load package\n",
        "\n",
        "Tutorial: https://www.tensorflow.org/tutorials/keras\n"
      ],
      "metadata": {
        "id": "XoMgN4yVtKcW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "import gensim.downloader as api\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.datasets import imdb\n",
        "\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "Nux1WuZmtLM1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings"
      ],
      "metadata": {
        "id": "iiM67hdb6f4_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train by yourself"
      ],
      "metadata": {
        "id": "dLALd7NTYRPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define training data\n",
        "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
        "             ['this', 'is', 'the', 'second', 'sentence'],\n",
        "             ['yet', 'another', 'sentence'],\n",
        "             ['one', 'more', 'sentence'],\n",
        "             ['and', 'the', 'final', 'sentence']]\n",
        "# train model\n",
        "model = Word2Vec(sentences, min_count=1, vector_size=20)\n",
        "\n",
        "# summarize the loaded model\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2swFBQpXdQL",
        "outputId": "3e981135-dece-4b13-c579-dcfcb725ad7d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=14, vector_size=20, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# access vector for one word\n",
        "print(model.wv['sentence'])"
      ],
      "metadata": {
        "id": "9ZJxlcWXYGQN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d483263-3b55-4689-9408-9799a7cf3a88"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00268114  0.00118216  0.02551675  0.04504637 -0.04651475 -0.03558404\n",
            "  0.03229436  0.04486494 -0.02507714 -0.01881686  0.03690252 -0.00766736\n",
            " -0.02268307  0.03277026 -0.0243008  -0.00908009  0.0143829   0.00495937\n",
            " -0.04142607 -0.04724409]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model\n",
        "model.save('model.bin')\n",
        "# load model\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "print(new_model)"
      ],
      "metadata": {
        "id": "7P7dMWYgYOa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc2d8f0-8876-49ac-f215-cdcbcd123b76"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=14, vector_size=20, alpha=0.025>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use trained"
      ],
      "metadata": {
        "id": "zr7GAIORYXuo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load glove vectors\n",
        "model = api.load(\"glove-twitter-25\")\n",
        "\n",
        "# show words that similar to word 'cat'\n",
        "model.most_similar(\"king\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hxWRnVz4fDN-",
        "outputId": "1164f6f6-4c13-4469-a707-b3312e556c93"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prince', 0.9337409734725952),\n",
              " ('queen', 0.9202421307563782),\n",
              " ('aka', 0.9176921844482422),\n",
              " ('lady', 0.9163240790367126),\n",
              " ('jack', 0.9147354364395142),\n",
              " (\"'s\", 0.9066898226737976),\n",
              " ('stone', 0.8982374668121338),\n",
              " ('mr.', 0.8919409513473511),\n",
              " ('the', 0.889343798160553),\n",
              " ('star', 0.8892088532447815)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(positive=['woman', 'king'], negative=['man'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bk_UsyrpZyRx",
        "outputId": "867a3d84-214d-4762-8a23-4ffab26980f7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('meets', 0.8841924071311951),\n",
              " ('prince', 0.832163393497467),\n",
              " ('queen', 0.8257461190223694),\n",
              " ('â€™s', 0.8174097537994385),\n",
              " ('crow', 0.813499391078949),\n",
              " ('hunter', 0.8131037950515747),\n",
              " ('father', 0.8115834593772888),\n",
              " ('soldier', 0.81113600730896),\n",
              " ('mercy', 0.8082392811775208),\n",
              " ('hero', 0.8082264065742493)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RNN\n",
        "Recurrent Neural Networks"
      ],
      "metadata": {
        "id": "N2nOBv2AXBry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "Se86EcmynXlL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_features = 20000\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "\n",
        "# Loading data\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = max_features)\n",
        "print(len(X_train), 'train sequences')\n",
        "print(len(X_test), 'test sequences')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHsgE4fZmBhu",
        "outputId": "6a453e05-f330-4d91-f5f5-a3fe417ed0fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000 train sequences\n",
            "25000 test sequences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen = 80)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen = 80)\n",
        "\n",
        "print('x_train shape:', X_train.shape)\n",
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bH0vXkprmDj4",
        "outputId": "ac42f111-dc81-4975-9913-821f6064a760"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (25000, 80)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwMk3WeHIDj6",
        "outputId": "a226b2b6-f524-42a3-ab72-c4969add968f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "5M6_gjXI8Lim"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### RNN"
      ],
      "metadata": {
        "id": "GMHq-RidQ0B4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Keras Sequential model\n",
        "RNN_model = keras.models.Sequential()\n",
        "RNN_model.add(keras.layers.Embedding(max_features, 128))\n",
        "RNN_model.add(keras.layers.SimpleRNN(128, dropout=0.2, recurrent_dropout=0.2, return_sequences= False))\n",
        "RNN_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "RNN_model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "RNN_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiUGUohMILQu",
        "outputId": "f3982b51-ac28-43f6-934c-8a6d68bf0228"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 128)               32896     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2593025 (9.89 MB)\n",
            "Trainable params: 2593025 (9.89 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute the model\n",
        "start_time = datetime.now() # Record the start time\n",
        "\n",
        "RNN_model.fit(X_train, y_train,\n",
        "              batch_size = 32,\n",
        "              epochs=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "# Record the run time\n",
        "end_time = datetime.now()\n",
        "RNN_time = end_time - start_time\n",
        "\n",
        "RNN_score, RNN_acc = RNN_model.evaluate(X_test, y_test, batch_size = 32)\n",
        "print('Test score:', RNN_score)\n",
        "print('Test accuracy:', RNN_acc)\n",
        "print('Duration: {}'.format(RNN_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3HeEi9IQhyQ",
        "outputId": "4bbab20f-e05d-4c6d-90c0-eb28bcd5d837"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 135s 163ms/step - loss: 0.6617 - accuracy: 0.5778 - val_loss: 0.4982 - val_accuracy: 0.7605\n",
            "782/782 [==============================] - 6s 8ms/step - loss: 0.4982 - accuracy: 0.7605\n",
            "Test score: 0.49816885590553284\n",
            "Test accuracy: 0.7605199813842773\n",
            "Duration: 0:02:23.739882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "I5p51X-8XDG1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Keras Sequential model\n",
        "LSTM_model = keras.models.Sequential()\n",
        "LSTM_model.add(keras.layers.Embedding(max_features, 128))\n",
        "LSTM_model.add(keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences= False))\n",
        "LSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "LSTM_model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "LSTM_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGOo8GmLmYtA",
        "outputId": "8fb2f8e0-7218-4e1a-c76b-3d84fc9b3362"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 128)               131584    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2691713 (10.27 MB)\n",
            "Trainable params: 2691713 (10.27 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute the model\n",
        "start_time = datetime.now() # Record the start time\n",
        "LSTM_model.fit(X_train, y_train,\n",
        "               batch_size = 32,\n",
        "               epochs=1,\n",
        "               validation_data=(X_test, y_test))\n",
        "\n",
        "# Record the run time\n",
        "end_time = datetime.now()\n",
        "LSTM_time = end_time - start_time\n",
        "\n",
        "LSTM_score, LSTM_acc = LSTM_model.evaluate(X_test, y_test, batch_size = 32)\n",
        "print('Test score:', LSTM_score)\n",
        "print('Test accuracy:', LSTM_acc)\n",
        "print('Duration: {}'.format(LSTM_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ouuKaILzrmeu",
        "outputId": "63269fb2-979f-49f2-a3d9-a30010f5ea57"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 319s 404ms/step - loss: 0.4387 - accuracy: 0.7888 - val_loss: 0.4824 - val_accuracy: 0.8235\n",
            "782/782 [==============================] - 20s 26ms/step - loss: 0.4824 - accuracy: 0.8235\n",
            "Test score: 0.48235321044921875\n",
            "Test accuracy: 0.8235200047492981\n",
            "Duration: 0:05:25.089539\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GRU"
      ],
      "metadata": {
        "id": "vppi8SLOX_hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Keras Sequential model\n",
        "GRU_model = keras.models.Sequential()\n",
        "GRU_model.add(keras.layers.Embedding(max_features, 128))\n",
        "GRU_model.add(keras.layers.GRU(128, dropout=0.2, recurrent_dropout=0.2, return_sequences= False))\n",
        "GRU_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "GRU_model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "GRU_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9f5PwxzYC7R",
        "outputId": "ac732bba-9d0d-4232-e01a-34b6edeb7ee1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer gru will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 128)               99072     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2659201 (10.14 MB)\n",
            "Trainable params: 2659201 (10.14 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute the model\n",
        "start_time = datetime.now() # Record the start time\n",
        "GRU_model.fit(X_train, y_train,\n",
        "               batch_size = 32,\n",
        "               epochs=1,\n",
        "               validation_data=(X_test, y_test))\n",
        "\n",
        "# Record the run time\n",
        "end_time = datetime.now()\n",
        "GRU_time = end_time - start_time\n",
        "\n",
        "GRU_score, GRU_acc = GRU_model.evaluate(X_test, y_test, batch_size = 32)\n",
        "print('Test score:', GRU_score)\n",
        "print('Test accuracy:', GRU_acc)\n",
        "print('Duration: {}'.format(GRU_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSU9-Ea5YDd6",
        "outputId": "a9056e24-6e3e-4a70-c719-5a6399861531"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 296s 374ms/step - loss: 0.4276 - accuracy: 0.7988 - val_loss: 0.3454 - val_accuracy: 0.8498\n",
            "782/782 [==============================] - 20s 25ms/step - loss: 0.3454 - accuracy: 0.8498\n",
            "Test score: 0.3454147279262543\n",
            "Test accuracy: 0.8497599959373474\n",
            "Duration: 0:05:24.805812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### biLSTM"
      ],
      "metadata": {
        "id": "6fLfjU5bOxEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Keras Sequential model\n",
        "biLSTM_model = keras.models.Sequential()\n",
        "biLSTM_model.add(keras.layers.Embedding(max_features, 128))\n",
        "biLSTM_model.add(keras.layers.Bidirectional(keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences= False)))\n",
        "biLSTM_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "biLSTM_model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "biLSTM_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6wPhb5KYLmH",
        "outputId": "c57b9d5c-f59b-47bf-f29e-31311694b91b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 256)               263168    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2823425 (10.77 MB)\n",
            "Trainable params: 2823425 (10.77 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute the model\n",
        "start_time = datetime.now() # Record the start time\n",
        "biLSTM_model.fit(X_train, y_train,\n",
        "               batch_size = 32,\n",
        "               epochs=1,\n",
        "               validation_data=(X_test, y_test))\n",
        "\n",
        "# Record the run time\n",
        "end_time = datetime.now()\n",
        "biLSTM_time = end_time - start_time\n",
        "\n",
        "biLSTM_score, biLSTM_acc = biLSTM_model.evaluate(X_test, y_test, batch_size = 32)\n",
        "print('Test score:', biLSTM_score)\n",
        "print('Test accuracy:', biLSTM_acc)\n",
        "print('Duration: {}'.format(biLSTM_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esLMlMsjYMsw",
        "outputId": "beaffeed-d69e-4d91-9cc4-0369c83a3aca"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 603s 763ms/step - loss: 0.4219 - accuracy: 0.8036 - val_loss: 0.3606 - val_accuracy: 0.8420\n",
            "782/782 [==============================] - 40s 51ms/step - loss: 0.3606 - accuracy: 0.8420\n",
            "Test score: 0.3606014847755432\n",
            "Test accuracy: 0.8419600129127502\n",
            "Duration: 0:10:27.922729\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### biLSTM_custom"
      ],
      "metadata": {
        "id": "fBRXDGGOEIoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the Keras Sequential model\n",
        "biLSTM_custom_model = keras.models.Sequential()\n",
        "biLSTM_custom_model.add(keras.layers.Embedding(max_features, 128))\n",
        "\n",
        "forward_layer = keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences= False)\n",
        "backward_layer = keras.layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences= False, go_backwards=True)\n",
        "\n",
        "biLSTM_custom_model.add(keras.layers.Bidirectional(forward_layer, backward_layer=backward_layer))\n",
        "biLSTM_custom_model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compiling the model\n",
        "biLSTM_custom_model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "biLSTM_custom_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2baZ1LtFEIFz",
        "outputId": "07f263b7-947b-4b0d-f3ec-145d91d451df"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, None, 128)         2560000   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, 256)               263168    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2823425 (10.77 MB)\n",
            "Trainable params: 2823425 (10.77 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalute the model\n",
        "start_time = datetime.now() # Record the start time\n",
        "biLSTM_custom_model.fit(X_train, y_train,\n",
        "               batch_size = 32,\n",
        "               epochs=1,\n",
        "               validation_data=(X_test, y_test))\n",
        "\n",
        "# Record the run time\n",
        "end_time = datetime.now()\n",
        "biLSTM_custom_time = end_time - start_time\n",
        "\n",
        "biLSTM_custom_score, biLSTM_custom_acc = biLSTM_custom_model.evaluate(X_test, y_test, batch_size = 32)\n",
        "print('Test score:', biLSTM_custom_score)\n",
        "print('Test accuracy:', biLSTM_custom_acc)\n",
        "print('Duration: {}'.format(biLSTM_custom_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-KtSncd6ERVj",
        "outputId": "e11c0e5a-3513-4bdc-c4c6-da3de7a50909"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 604s 763ms/step - loss: 0.4231 - accuracy: 0.8012 - val_loss: 0.3577 - val_accuracy: 0.8407\n",
            "782/782 [==============================] - 38s 48ms/step - loss: 0.3577 - accuracy: 0.8407\n",
            "Test score: 0.3577262759208679\n",
            "Test accuracy: 0.8406800031661987\n",
            "Duration: 0:10:28.919293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compare"
      ],
      "metadata": {
        "id": "g5V8WZXVMhKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('RNN Test accuracy:', RNN_acc)\n",
        "print('LSTM Test accuracy:', LSTM_acc)\n",
        "print('GRU Test accuracy:', GRU_acc)\n",
        "print('biLSTM Test accuracy:', biLSTM_acc)\n",
        "print('biLSTM_custom Test accuracy:', biLSTM_custom_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQLRVZDKMjiu",
        "outputId": "1bbf296a-e59e-4194-ed90-dbf344c027f2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN Test accuracy: 0.7605199813842773\n",
            "LSTM Test accuracy: 0.8235200047492981\n",
            "GRU Test accuracy: 0.8497599959373474\n",
            "biLSTM Test accuracy: 0.8419600129127502\n",
            "biLSTM_custom Test accuracy: 0.8406800031661987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('RNN Test accuracy:', RNN_time)\n",
        "print('LSTM Test accuracy:', LSTM_time)\n",
        "print('GRU Test accuracy:', GRU_time)\n",
        "print('biLSTM Test accuracy:', biLSTM_time)\n",
        "print('biLSTM_custom Test accuracy:', biLSTM_custom_time)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AeE86qYYNEy3",
        "outputId": "9ebc89ee-d97a-43c1-865c-3e7fd68e6982"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN Test accuracy: 0:02:23.739882\n",
            "LSTM Test accuracy: 0:05:25.089539\n",
            "GRU Test accuracy: 0:05:24.805812\n",
            "biLSTM Test accuracy: 0:10:27.922729\n",
            "biLSTM_custom Test accuracy: 0:10:28.919293\n"
          ]
        }
      ]
    }
  ]
}